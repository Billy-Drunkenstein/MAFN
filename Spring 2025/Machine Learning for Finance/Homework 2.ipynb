{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Billy-Drunkenstein/MAFN/blob/main/Spring%202025/Machine%20Learning%20for%20Finance/Homework%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Context of the problem**\n",
        "\n",
        "The problem centers around trying to predict S&P 500 stock market movements using:\n",
        "\n",
        "Volatility Index, which measures market sentiment and expected volatility\n",
        "\n",
        "Crude Oil Futures, which can serve as a proxy for global economic activity.\n",
        "\n",
        "Gold Futures, often used as a safe-haven asset during times of market stress.\n",
        "\n",
        "The respective tickers for each of these items are the following:\n",
        "\n",
        "^GSPC = SP500\n",
        "\n",
        "^VIX = Volatility index\n",
        "\n",
        "CL=F = Crude oil futures\n",
        "\n",
        "GC=F = Gold futures"
      ],
      "metadata": {
        "id": "Xwunvko1Ju6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(0 points) Prerequisite - run the code to import the necessary modules**"
      ],
      "metadata": {
        "id": "aa9kgtXGnXib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "#Used to download historical market data from Yahoo Finance via its API\n",
        "\n",
        "import pandas as pd\n",
        "#Provides DataFrame objects and data manipulation tools\n",
        "\n",
        "import numpy as np\n",
        "#Provides numerical operations, including functions for arrays and calculations\n",
        "\n",
        "import datetime\n",
        "#Used for working with dates (for example, to generate today’s date)\n",
        "\n",
        "from sqlalchemy import create_engine\n",
        "#Creates a connection (engine) to an SQLite database.\n",
        "\n",
        "import sqlite3\n",
        "#sqlite3 is imported as well, although in this code the SQLAlchemy engine is used to handle database I/O\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "#sklearn.metrics:Provides functions such as accuracy_score and classification_report to evaluate model performance\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "#\t•\tsklearn.linear_model: Provides linear models: LogisticRegression is used to fit classification models with various regularization methods. SGDClassifier is a stochastic gradient descent classifier that can be trained incrementally (allowing for iteration callbacks).\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#KNeighborsClassifier (for k-nearest neighbors\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "#SVC (for support vector machines)\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "#DecisionTreeClassifier (for decision trees)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#RandomForestClassifier (for random forests)"
      ],
      "metadata": {
        "id": "cev6frD220Fx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(0 points)Prerequisite - how to download data from Yahoo Finance without having a premium subscription**\n",
        "\n",
        "*Option 1: Excel*\n",
        "\n",
        "1) Go in browser to finance.yahoo.com put stock ticker in a box\n",
        "\n",
        "\n",
        "2) On the left select HISTORICAL DATA\n",
        "\n",
        "\n",
        "3) For period select MAX\n",
        "\n",
        "\n",
        "4) SELECT ALL from table then COPY\n",
        "\n",
        "\n",
        "5) Open new sheet of excel in excel select PASTE AS HTML\n",
        "\n",
        "\n",
        "6) Delete any extra data from Excel\n",
        "\n",
        "\n",
        "7) Import the data from the Excel file\n",
        "\n",
        "*Option 2: Yahoo Finance workaround*\n",
        "\n",
        "Run this python code to download the data.\n",
        "\n",
        "!pip install yfinance openpyxl\n",
        "\n",
        "-------------------------\n",
        "\n",
        "msft_data = yf.download(\"MSFT\", start=\"2014-01-24\", end=\"2025-01-15\", interval=\"1d\", auto_adjust=False)\n",
        "\n",
        "if \"Adj Close\" not in msft_data.columns and \"Adj Close\" in msft_data.columns.str.lower():\n",
        "    msft_data.rename(columns={\"adj close\": \"Adj Close\"}, inplace=True)\n",
        "\n",
        "file_path = \"MSFT_Historical_Data.xlsx\"\n",
        "msft_data.to_excel(file_path, engine=\"openpyxl\")"
      ],
      "metadata": {
        "id": "7LXq6kIRF2QE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task 1 - Data preparation and exploration**\n",
        "\n"
      ],
      "metadata": {
        "id": "eMhJ-o1KvWNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(10 points) Task 1.1 - Create a function to download data via API. Hint: Data will be downloaded from Yahoo Finance"
      ],
      "metadata": {
        "id": "O4YlcyEYpO5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_data(tickers, start_date, end_date):\n",
        "    \"\"\"\n",
        "    Downloads historical 'Adj Close' or 'Close' data for the given tickers from Yahoo Finance.\n",
        "    Handles cases where 'Adj Close' is missing.\n",
        "    \"\"\"\n",
        "    data_dict = {}\n",
        "    for ticker in tickers:\n",
        "\n",
        "        # Now check if 'Adj Close' column exists. If not, use 'Close'\n",
        "\n",
        "        # Now keep only the relevant price column and rename it to the ticker\n",
        "\n",
        "    # Merge the data on the date index (inner join)\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "FxI_NhIYpKSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(10 points) Task 1.2 - Create a function to clean the data. Hint: Drop the rows with missing values.\n",
        "\n",
        "Calculate the daily percentage change (return) for the S&P 500. Create a binary target variable: 1 if the next day's S&P 500 return > 0, else 0.\n"
      ],
      "metadata": {
        "id": "f_6PVto_pQ8R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(df):\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "ofTuLLwDrvgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(10 points) Task 1.3 - Create a function to save the data to a local database"
      ],
      "metadata": {
        "id": "y7RvEx9KpSQI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_db(df, db_name='market_data.db', table_name='market_data'):"
      ],
      "metadata": {
        "id": "ssNY-GiUrnzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(10 points) Task 2 – Create a function to split the Data into Train, Test, and Validation Sets**. Hint: Ensure the data is sorted by date first."
      ],
      "metadata": {
        "id": "VUtv79k_sbnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(df, feature_columns, target_column):\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "xrNXwOPmsbRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(10 points) Task 3.1 - Create a function to analyse the data applying loss functions and regularisation functions such as ridge and lasso regulsatisation**"
      ],
      "metadata": {
        "id": "dnSmHqeYwT_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def logistic_regression_models(X_train, y_train, X_val, y_val):"
      ],
      "metadata": {
        "id": "9yBrJcFew2r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(15 points) Task 4 - Create an iteration callback function to print information for troubleshooting**\n",
        "\n",
        "During each epoch, the callback should print:\n",
        "A. The current epoch number.\n",
        "B. The loss value for that epoch.\n",
        "C. The training accuracy for that epoch.\n",
        "\n",
        "Comment on how the loss evolves over the epochs and whether this trend indicates proper convergence?"
      ],
      "metadata": {
        "id": "lIaSJNJ0wo9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd_classifier_with_callback(X_train, y_train, n_epochs=10):\n",
        "\n",
        "    return"
      ],
      "metadata": {
        "id": "ValL-RThwkZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(10 points) Task 5 - Create a function to explore classification algorithms in the following order: Nearest Neighbor,SVM, Decision Trees and Random Forest**.\n",
        "\n",
        "Using the features from your dataset, your goal is to predict whether the S&P 500’s next-day return will be positive (1) or negative (0).\n",
        "\n",
        "For each algorithm, compute and report accuracy on the test set and a detailed classification report (including precision, recall, and F1-score).\n",
        "\n",
        "Hint: This can all be done within a single function, using a for loop."
      ],
      "metadata": {
        "id": "d_CTpcudw0Qg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def explore_classification_algorithms(X_train, y_train, X_test, y_test):"
      ],
      "metadata": {
        "id": "BDWHRCiP0N1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(15 points) Task 6 - Create a simple data pipeline, which can be a scheduled script.** Hint: This serves as the main entry point that strings together all of the previous functions to form a complete data pipeline. This should be scheduled at regular intervals."
      ],
      "metadata": {
        "id": "neWgpxISwH9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline():"
      ],
      "metadata": {
        "id": "zss17mUfDmRU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(10 points) Task 7 - What does the accuracy of each method used seem to be? What does this tell us both about the data that we used to train our prediction model and the predictive techniques which we tried to implement?**"
      ],
      "metadata": {
        "id": "GpHuI5lkDoX_"
      }
    }
  ]
}