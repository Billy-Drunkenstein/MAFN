{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNy0uqsx7s7XgVmIxcanfHo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#MATHGR5430 MACHINE LEARNING FOR FINANCE, SPRING 2025\n","<center>\n","<h1>Homework 3</h1>\n","</center>\n","\n","\n","## Background\n","You are a data scientist at a credit card company. A new dataset just landed in front of you. Your manager asked you to predict whether a client will make a large amount of payment(large 'payment' column). Before diving into modeling, you need to make the data usable. (Check datacard.txt) All the questions are based on this data set."],"metadata":{"id":"aP_gK0YaxFm0"}},{"cell_type":"markdown","source":["## Question 1"],"metadata":{"id":"_du8C5ywyN2r"}},{"cell_type":"markdown","source":["1.1 Data Cleaning\n","\n","Import the dataset as a pandas dataframe. (Google is your best friend here, mount your google drive to colab and read your csv there)\n","\n"],"metadata":{"id":"W9K6DzwPxsEt"}},{"cell_type":"markdown","source":["Drop a irrelevant features (Hint: there is a column should never be use for any prediction and should not affect the prediction model, drop that one).\n"],"metadata":{"id":"gEhuAHgRxvcj"}},{"cell_type":"markdown","source":["\n","Identify and replace missing values (with any justifable approach to maintain datasize).\n","\n"],"metadata":{"id":"14Mttd-Txveo"}},{"cell_type":"markdown","source":["Identify and replace outliers. Justify your approach.\n","\n"],"metadata":{"id":"k0X0ox8sxvh6"}},{"cell_type":"markdown","source":["1.2 Exploratory Data Analysis\n","\n","Plot the correlation matrix. What relationships or multicollinearity do you observe?\n","\n"],"metadata":{"id":"2xVsaE6sxvj8"}},{"cell_type":"markdown","source":["Provide summary statistics and visualizations (e.g., histograms, boxplots) for key variables like PURCHASES, CREDIT_LIMIT, PAYMENTS, MINIMUM_PAYMENTS, etc.\n","\n"],"metadata":{"id":"7nm_HbDRxvlq"}},{"cell_type":"markdown","source":["Create a binary label HIGH_PAYMENT where:\n","HIGH_PAYMENT = 1 if PAYMENTS > 4000 else 0"],"metadata":{"id":"lmMfaXvDxvnX"}},{"cell_type":"markdown","source":["## Question 2 Supervised Learning with KNN and Ensemble Models Now that your dataset is cleaned and labeled, you will try to predict whether a customer will make a high payment using supervised learning."],"metadata":{"id":"I_Fn37rExvpb"}},{"cell_type":"markdown","source":["2.1 Distance-Based Learning Normalize your features and explain why this step is important for KNN.\n","\n"],"metadata":{"id":"s9YN3jXTybEd"}},{"cell_type":"markdown","source":["Train a K-Nearest Neighbors classifier to predict HIGH_PAYMENT.\n","\n"],"metadata":{"id":"1JmdQVdmzhLT"}},{"cell_type":"markdown","source":["Pick a reasonable k. (restrict to only 3-5 , you can try elbow method , it will not work well in this case), Justify your pick.\n","\n"],"metadata":{"id":"5cMaooa6zhNX"}},{"cell_type":"markdown","source":["Evaluate your model using a confusion matrix and performance metrics: Accuracy, Precision, Recall, F1-score.\n"],"metadata":{"id":"H8fq5JpszhRQ"}},{"cell_type":"markdown","source":["\n","Try computing both Euclidean and Cosine distance manually for a small sample of data points."],"metadata":{"id":"9A30uHEQzhTP"}},{"cell_type":"markdown","source":["2.2 Linear Discriminant Analysis (LDA)\n","\n","Explain the concept of LDA and scatter matrices.\n","\n"],"metadata":{"id":"ZZrmwRw0ycCG"}},{"cell_type":"markdown","source":["Apply LDA to reduce your data to justifyable dimensions.\n","\n"],"metadata":{"id":"mzOX1EFZzwxR"}},{"cell_type":"markdown","source":["Visualize the result and interpret the separation between classes."],"metadata":{"id":"QbLBIMezzwzl"}},{"cell_type":"markdown","source":["2.3 Ensemble Learning Train two different classifiers:\n","\n","Logistic Regression – adjust the regularization rates (try values like 0.01, 0.1, 1, 10).\n","\n","SGDClassifier (Stochastic Gradient Descent Classifier) – experiment with different learning rates (eta0) and regularization penalties (l2, l1, etc.)\n","\n","Suggested settings to try:\n","\n","penalty = 'l2', eta0 = 0.01, 0.1, 1\n","\n","\n","Hint: If you are comfortable using third-party packages, you may optionally try XGBoostClassifier and explore learning_rate and reg_lambda.\n","\n","Combine the two models using a simple ensemble method (e.g., majority voting).\n","\n"],"metadata":{"id":"j-PjDdzmycEa"}},{"cell_type":"markdown","source":["Evaluate the performance of each model and the ensemble using:\n","\n","Accuracy, Precision, Recall, F1-score\n","\n"],"metadata":{"id":"6MeWPKhZz_9B"}},{"cell_type":"markdown","source":["Briefly describe:\n","\n","How changes in regularization and learning rate affected model performance.\n","\n"],"metadata":{"id":"vNAY2RsFz__V"}},{"cell_type":"markdown","source":["Which combination performed best, and why you think that happened."],"metadata":{"id":"rnCtHWq20ABL"}},{"cell_type":"markdown","source":["## Question 3 Unsupervised Learning and Dimensionality Reduction Your manager wants you to group customers based on their behavior and understand patterns without relying on labels."],"metadata":{"id":"hr3NdVvZycGv"}},{"cell_type":"markdown","source":["3.1 Principal Component Analysis (PCA) Normalize the data.\n","\n","Apply PCA and report the explained variance of the first 3 components.\n","\n"],"metadata":{"id":"XlzTuiCcyrhQ"}},{"cell_type":"markdown","source":["Visualize the data in the PCA space (3D plot).\n","\n"],"metadata":{"id":"R4mYPkMa0c-G"}},{"cell_type":"markdown","source":["Interpret whether the data is well-represented in the new space."],"metadata":{"id":"kgUaRSgq0c_5"}},{"cell_type":"markdown","source":["3.2 K-Means Clustering Use the PCA-transformed data. Plot the Elbow Curve for k values from 2 to 10 using both random and kmeans++ initialization. find the optimal K.\n","\n"],"metadata":{"id":"73thZzvzyrr3"}},{"cell_type":"markdown","source":["Fit the final model and visualize the clusters in 3D.\n","\n"],"metadata":{"id":"uq5UqWwbyruG"}},{"cell_type":"markdown","source":["Repeat clustering on the original (non-PCA) data. Choose 5 features and plot their distributions cluster by cluster.\n","\n"],"metadata":{"id":"MWRK6NDdyrwM"}},{"cell_type":"markdown","source":["Compare clustering results before and after PCA. Which works better and why?"],"metadata":{"id":"KH7T7qFK0mmz"}}]}